{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import retrieval_qa\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import ctransformers\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain_community.vectorstores import Pinecone as langchainPinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa24a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connected to existing index 'medical-chatbot'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import classes\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Step 2:  Pinecone API key\n",
    "PINECONE_API_KEY = \"pcsk_bkA7R_QrV1CyjrzUqiiVJrbb4cwySPnt6PsVgn2QfHq6ys8eWyAy3gFK5vGgtYLRCsT3x\"\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "#Step 4: Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Step 5: Connect to existing index\n",
    "index = pc.Index(index_name)\n",
    "print(f\" Connected to existing index '{index_name}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b82d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from PDF\n",
    "def load_pdf(data):\n",
    "    loader=DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbda5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67248827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text chunks \n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of my chunks: 39994\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of my chunks:\",len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd7f6eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\medical_book.pdf', 'page': 1}, page_content='The GALE\\nENCYCLOPEDIA of\\nMEDICINE\\nTHIRD EDITION')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a523cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download embedding model \n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c5475fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd7097a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "09326f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Length\",len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "72045272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY  # âœ… This line is the fix\n",
    "\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Connect to index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "limited_chunks = text_chunks[:10000]\n",
    "# Upload using Langchain\n",
    "docsearch = PineconeVectorStore.from_texts(\n",
    "    texts=[t.page_content for t in limited_chunks],\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    "    namespace=\"default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df64cbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result []\n"
     ]
    }
   ],
   "source": [
    "# If we already have an index we can load it like this\n",
    "docsearch = PineconeVectorStore.from_existing_index(index_name,embeddings)\n",
    "\n",
    "query = \"What are Allergies\"\n",
    "\n",
    "docs = docsearch.similarity_search(query,k=3)\n",
    "\n",
    "print(\"Result\",docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29cc22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_template = \"\"\"Use the following pieces of information to answer the \n",
    "user question . if you dont know the answer, just say that you dont know , dont try to makeup the answer\n",
    "\n",
    "context:{context}\n",
    "question:{question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7af3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=Prompt_template,input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs = {\"prompt\":PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d352a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load LLM\n",
    "llm = CTransformers(\n",
    "    model=\"E:/5)End-To-End-Medical-Chatbot/model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.8\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(f\"Input Prompt:\")\n",
    "    result = qa({\"query\":user_input})\n",
    "    print(\"Response:\",result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
